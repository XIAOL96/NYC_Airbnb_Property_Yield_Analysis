rm(list = ls())
setwd('~/Downloads')
library(readr)
library(dplyr)
require(dplyr)
library(ggplot2)

# read data

nyc_listings = read.csv('listings.csv', sep = ",", na.strings = c("", "NA", "N/A")) #49056*96

          ### preprocessing 

cols_to_keep = c(
  'description', 
  'property_type', 'room_type', 'accommodates',
  'bathrooms', 'bedrooms', 'beds', 'square_feet',
  'price', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights',
  'availability_365', 'reviews_per_month', 'latitude', 'longitude', 'bed_type',
  'amenities')

nyc_listings = nyc_listings[cols_to_keep]

for (x in c(which(colnames(nyc_listings) %in% c("price", "cleaning_fee", 
                                                "extra_people")))){
  nyc_listings[,x] = as.numeric(gsub("\\$|,", "", nyc_listings[,x]))}


# remove cols which have more than 80% missing values
nyc_listings = nyc_listings %>% dplyr::select(-which(colSums(is.na(nyc_listings))/dim(nyc_listings)[1] > 0.8)) 

# make sure they are highly available 
nyc_listings = nyc_listings[which(nyc_listings$availability_365 > 60),]     #25427 obs

nyc_listings$average_length_of_stay = ifelse(nyc_listings$minimum_nights > 6.4,
                                             nyc_listings$minimum_nights,
                                             6.4)
nyc_listings$minimum_nights = NULL

nyc_listings$yield = nyc_listings$average_length_of_stay * 
  nyc_listings$price * 
  nyc_listings$reviews_per_month / 0.5 * 12 

nyc_listings = nyc_listings[-which(is.na(nyc_listings$yield)),]  #21044


nyc_listings = nyc_listings[-which(is.na(nyc_listings$description)),] #20891

summary(is.na(nyc_listings))

nyc_listings = nyc_listings[-which(is.na(nyc_listings$description)),]

nyc_listings$bathrooms = ifelse(is.na(nyc_listings$bathrooms), 
                                    median(nyc_listings$bathrooms, na.rm = T),  
                                    nyc_listings$bathrooms )

nyc_listings$bedrooms = ifelse(is.na(nyc_listings$bedrooms), 
                                   median(nyc_listings$bedrooms, na.rm = T),  
                                   nyc_listings$bedrooms)

nyc_listings$beds = ifelse(is.na(nyc_listings$beds), 
                               median(nyc_listings$beds, na.rm = T),  
                               nyc_listings$beds )

nyc_listings$cleaning_fee= ifelse(is.na(nyc_listings$cleaning_fee), 
                                      median(nyc_listings$cleaning_fee, na.rm = T),  
                                      nyc_listings$cleaning_fee)

nyc_listings = nyc_listings %>% dplyr::select(-c(price, average_length_of_stay, reviews_per_month))
summary(is.na(nyc_listings))

# code property_type
levels(nyc_listings$property_type)[which(levels(nyc_listings$property_type) == 'Serviced apartment')] = 'Apartment'
levels(nyc_listings$property_type)[which(!levels(nyc_listings$property_type) %in% c("Apartment", "Condominium", "Loft",
                                                                                            "House","Townhouse"))] = 'Others'

nyc_listings = nyc_listings[which(nyc_listings$yield != 0),]    #20877


# fit a linear regression model
lr = lm(yield ~. , data = nyc_listings[,-c(1,16])
summary(lr)

n = dim(nyc_listings)[1] 
# number of parameters
p = dim(nyc_listings)[2]-1

# get t-statistic
jack = rstudent(lr)
nyc_listings = nyc_listings[-which(abs(jack) > abs(qt(.05/(2*n), n-p-1))),]   #20653


# get cook's distance
cook = cooks.distance(lr)
# makes a half-normal plot to show cook's distance
faraway::halfnorm(cook, labs=row.names(nyc_listings[,-1]), ylab="Cook's distances")
# no influential points found


#refit linear regression
lr1 = lm(yield ~. , data = nyc_listings[,-1])
summary(lr1)

#stepwise selection
library(MASS)    
step.model <- stepAIC(lr1, direction = "both", 
                      trace = FALSE)
summary(step.model)

write.csv(nyc_listings, "nyc_listings.csv")

new_nyc_listings = read.csv("new_nyc_listings.csv")
new_nyc_listings = new_nyc_listings[,-1]
colnames(new_nyc_listings)[16] = 'topic'

lr2  = lm(yield ~. , data = new_nyc_listings[,-1])
summary(lr2)










